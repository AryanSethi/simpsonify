{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aryan\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Aryan\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\Aryan\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from numpy import asarray\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D,Input,LeakyReLU,Activation,Concatenate,BatchNormalization,Conv2DTranspose\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from random import random\n",
    "from numpy.random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGAN:\n",
    "    #general discriminator model\n",
    "    @staticmethod\n",
    "    def discriminator(image_shape):\n",
    "        init = RandomNormal(stddev = 0.02)  #initializer\n",
    "        in_image = Input(shape=(image_shape,image_shape,3))\n",
    "        \n",
    "        d = Conv2D(64,(4,4),strides=(2,2),padding='same', kernel_initializer=init)(in_image)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        \n",
    "        d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "        d = InstanceNormalization(axis=-1)(d)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        \n",
    "        d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "        d = InstanceNormalization(axis=-1)(d)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        \n",
    "        d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "        d = InstanceNormalization(axis=-1)(d)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        \n",
    "        d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "        d = InstanceNormalization(axis=-1)(d)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        \n",
    "        patch_out = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "        \n",
    "        model = Model(in_image, patch_out)\n",
    "        \n",
    "        model.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5), loss_weights=[0.5])\n",
    "        return model\n",
    "    \n",
    "    #resnet blocks going to be used in generator models\n",
    "    def resnet_block(n_filters, input_layer):\n",
    "        init = RandomNormal(stddev=0.02)\n",
    "\n",
    "        g = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(input_layer)\n",
    "        g = InstanceNormalization(axis=-1)(g)\n",
    "        g = Activation('relu')(g)\n",
    "\n",
    "        g = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(g)\n",
    "        g = InstanceNormalization(axis=-1)(g)\n",
    "\n",
    "        g = Concatenate()([g, input_layer])\n",
    "        return g\n",
    "    \n",
    "    #general generator model\n",
    "    @staticmethod\n",
    "    def generator(image_shape, n_resnet=9):\n",
    "        init = RandomNormal(stddev=0.02)\n",
    "    \n",
    "        in_image = Input(shape=(image_shape,image_shape,3))\n",
    "    \n",
    "        g = Conv2D(64, (7,7), padding='same', kernel_initializer=init)(in_image)\n",
    "        g = InstanceNormalization(axis=-1)(g)\n",
    "        g = Activation('relu')(g)\n",
    "\n",
    "        g = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "        g = InstanceNormalization(axis=-1)(g)\n",
    "        g = Activation('relu')(g)\n",
    "\n",
    "        g = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "        g = InstanceNormalization(axis=-1)(g)\n",
    "        g = Activation('relu')(g)\n",
    "\n",
    "        for _ in range(n_resnet):\n",
    "            g = CGAN.resnet_block(256, g)\n",
    "\n",
    "        g = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "        g = InstanceNormalization(axis=-1)(g)\n",
    "        g = Activation('relu')(g)\n",
    "\n",
    "        g = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "        g = InstanceNormalization(axis=-1)(g)\n",
    "        g = Activation('relu')(g)\n",
    "\n",
    "        g = Conv2D(3, (7,7), padding='same', kernel_initializer=init)(g)\n",
    "        g = InstanceNormalization(axis=-1)(g)\n",
    "        out_image = Activation('tanh')(g)\n",
    "\n",
    "        model = Model(in_image, out_image)\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    # General composite model : \n",
    "    #  Arguments ->   \n",
    "    #    g_model_1:trainable generator  ,  d_model:disc model just after previous generator  ,  g_model_2:second gen for cycle\n",
    "    @staticmethod\n",
    "    def composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
    "        g_model_1.trainable = True\n",
    "\n",
    "        d_model.trainable = False\n",
    "\n",
    "        g_model_2.trainable = False\n",
    "\n",
    "        input_gen = Input(shape=(image_shape,image_shape,3))\n",
    "        gen1_out = g_model_1(input_gen)\n",
    "        output_d = d_model(gen1_out)\n",
    "\n",
    "        input_id = Input(shape=(image_shape,image_shape,3))\n",
    "        output_id = g_model_1(input_id)\n",
    "\n",
    "        output_f = g_model_2(gen1_out)\n",
    "\n",
    "        gen2_out = g_model_2(input_id)\n",
    "        output_b = g_model_1(gen2_out)\n",
    "       \n",
    "        model = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
    "\n",
    "        opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "        model.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=opt)\n",
    "        return model\n",
    "    \n",
    "    #fake image pool management\n",
    "    def update_image_pool(pool, images, max_size=50):\n",
    "        selected = []\n",
    "        for image in images:\n",
    "            if len(pool) < max_size:\n",
    "                pool.append(image)\n",
    "                selected.append(image)\n",
    "            elif random() < 0.5:\n",
    "                selected.append(image)\n",
    "            else:\n",
    "                ix = randint(0, len(pool))\n",
    "                selected.append(pool[ix])\n",
    "                pool[ix] = image\n",
    "        return asarray(selected)\n",
    "    \n",
    "    def generate_real_samples(data,n_samples,used,patch_size):\n",
    "        ix = randint(0,len(data),n_samples)\n",
    "        x = data[ix]\n",
    "        y = np.ones((n_samples,patch_size,patch_size,1))\n",
    "        used.append(ix)\n",
    "        return x,y\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def train(disc_A,disc_B,gen_A,gen_B,comp_A,comp_B,data,EPOCHS=20,batch_size=1):\n",
    "        pool_h,pool_s = list(),list()\n",
    "        used_images_s,used_images_h = list(),list()         #to keep track of used real images selected randomly\n",
    "        patch_size = disc_A.output_shape[1]\n",
    "        batches_per_epoch = int(len(data)/batch_size)\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            print(f\"[INFO] Starting epoch {epoch} of {EPOCHS}.....\")\n",
    "            for batch in range(batches_per_epoch):\n",
    "                real_h_x,real_h_y = generate_real_samples(data,batch_size,used_images_s,patch_size)\n",
    "                real_s_x,real_s_y = generate_real_samples(data,batch_size,used_images_s,patch_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
